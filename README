Chirag Sakhuja
csid: csakhuja

 _______  _______          
(  ____ \(  ____ )|\     /|
| (    \/| (    )|| )   ( |
| |      | (____)|| |   | |
| | ____ |  _____)| |   | |
| | \_  )| (      | |   | |
| (___) || )      | (___) |
(_______)|/       (_______)
                           

Overview
====
The goal of my project was to design and implement a GPU. In this report, I will document my
progress and talk about improvements I can make (aka, I didn't fully finish).


Design
====
The resolution of the screen is 640x480. To draw to the screen, I keep track of two "framebuffers".
A framebuffer is simply a block of memory that can be used to update the pixels on the screen. One
advantage of using a framebuffer is that you can render an entire frame and then output it at once.
This prevents the screen from having a "tearing" effect.

I used two framebuffers for my GPU. The first framebuffer is used by the HDMI driver to lookup the colors
of pixels to render. The second is used by the shader cores to rasterize the next frame. This technique
is called double buffering. Double buffering allows a seamless swap between the frame that is rendering 
and the frame that is being computed. This way, the shader cores can compute the next frame without making
the HDMI driver wait on the framebuffer. This typically lends itself to better visual performance and less 
I/O blocking.

I swapped the framebuffers by maintaing a global register that indicated which framebuffer the rasterizer
(shader cores) should use and which one the renderer (HDMI driver) should use. Each of the shader cores
has a ready signal that indicates it has computed the color of all pixels in its block. The computation can
be done by executing a small program, called a fragment shader, for each pixel in a block (more on that
below). These programs can behave differently for each pixel, so the shader cores may not necessarily complete
their execution at the same time. Individual shader cores pause until all of them are complete. Once all
the shader cores have announced that they are ready, the framebuffer switch occurs. At this time, the rasterizer
sends a signal to the shader cores that indicates they can resume operation with the new framebuffer.
Using these signals, I am able to synchronize swapping between the renderer and rasterizer. I experimented
with different clock speeds for the shader cores and HDMI driver, but there was no noticeable difference in
performance.

Each of my framebuffers were 160x120x8 bit blocks of memory (specifically 1M10K blocks). I scaled the
resolution down to one quarter of the screen size to consume less resources on the board. I also decided
to use 8-bit color depth. Furthermore, I broke each framebuffer into a grid 16x16x8 bit blocks. This
means there are 10x7.5 blocks on each framebuffer. I created one shader core per block.

The purpose of a shader core is to iterate through all the pixels in it's block and perform some calculation
on them. A naive GPU could have one shader core for the entire framebuffer, making it perform the same
operation for all 19200 pixels, every single frame. As mentioned earlier, I have broken my framebuffers into
10x7.5 blocks, so I have 80 shader cores total.

A shader core is nothing more than a simple pipelined processor. Each shader core can run a program, often
called a "fragment shader" per pixel. The purpose of the pipeline is to execute the fragment shader for every
pixel in a block and generate a color value for the pixel. By introducing 80 shader cores, I am able to compute
and render the pixels in a much smaller timeframe. Pixe-level computations are genearlly easy to parallelize, so the
shader cores act like independent blocks, all running in parallel. This is a significant improvement over the
naive method, as it actually does reduce rasterization time by 80 times.

I created a very simple 16-bit ISA for the fragment shader programs.

         __________________________________________________
        |           |  |         |   |       |             |
  ADDI  |  0 0 0 0  |  |   SR1   |   |  DR   |  Immediate  |
        |___________|__|_________|___|_______|_____________|
        15        12 11 10      9  8  7     4 3          0

         __________________________________________________
        |           |  |         |   |       |   |         |
  ADD   |  0 0 0 1  |  |   SR1   |   |  DR   |   |   SR2   |
        |___________|__|_________|___|_______|___|_________|
        15        12 11 10      9  8  7     4  3  2       0

         __________________________________________________
        |           |  |         |   |       |             |
  SUBI  |  0 0 1 0  |  |   SR1   |   |  DR   |  Immediate  |
        |___________|__|_________|___|_______|_____________|
        15        12 11 10      9  8  7     4 3          0

         __________________________________________________
        |           |  |         |   |       |   |         |
  SUB   |  0 0 1 1  |  |   SR1   |   |  DR   |   |   SR2   |
        |___________|__|_________|___|_______|___|_________|
        15        12 11 10      9  8  7     4  3  2       0

         _________________________________________________
        |           |  |         |                        |
   LD   |  0 1 0 0  |  |   DR    |       PC Offset        |
        |___________|__|_________|________________________|
        15        12 11 10      9  8                      0

         _________________________________________________
        |           |  |         |                        |
   ST   |  0 1 0 1  |  |   SR    |       PC Offset        |
        |___________|__|_________|________________________|
        15        12 11 10      9  8                      0

         _________________________________________________
        |           |  |         |                        |
  BRp   |  1 1 1 0  |  |   SR    |       PC Offset        |
        |___________|__|_________|________________________|
        15        12 11 10      9  8                      0

         _________________________________________________
        |           |  |         |                        |
  BRn   |  1 1 1 1  |  |   SR    |       PC Offset        |
        |___________|__|_________|________________________|
        15        12 11 10      9  8                      0


The shader programs can be written and loaded using the program.mif file. It is important to note
that the pipeline implementation is very simple. Each shader core uses a 5 stage pipeline. There
is no dependency checking, so it is essential to place NOP instrucions (encoded as 0x0000) between
dependent instructions and after branches. Also, there is no initialization process, so the first
two instructions must also be NOP.

Unfortunately, I only had time to implement the LD and ST instructions. I chose to implement these
instructions because I introduced simple memory-mapped I/O. To make neat looking effects on the GPU,
a fragment shader typically needs to know some information about the pixel. One piece of information
is the actual coordinate of the pixel on the screen. This allows you to change the behavior of a pixel
based on its absolute position. Here is a mapping of the memory addresses

	x20: pixel x coordinate
	x21: pixel y coordinate
	x22, x22: customizable value sent from renderer

	If there are _any_ stores to memory mapped I/O, the pipeline assumes it will be the pixel color
	and that the pipeline is ready.

The address are so low because I only provide 32 words of memory for the shader program. Once again,
this was due to memory constraints on the board (not total memory, but total number of 1M10k blocks).

Each shader core has one pipeline in it. The shader core iterates through all the pixels and supplies
data to the pipeline so that it can compute the pixel's color. I also pipeline the operation of streaming
pixel information to the pipeline, so there is no delay with restarting the fragment shader on a new pixel.

Note that the purpose of each pipeline is simply to compute a pixel value. This value is communicated in
the pipeline by announcing to the shader core that the value is ready, and then broadcasting it to the
memory-mapped I/O. The shader cores picks up the value, writes it to the rasterization framebuffer,
and then moves onto the next pixel, restarting the fragment shader in the process.


Demo
====
The demo program shows how the individual cores run together to rasterize the entire framebuffer. The
idea was to statically map the position of a pixel to its color. However, for some reason the pixel
values were not persisting. In the actual demo, you will notice that only one pixel per block stays
the correct color, and the other pixels move through a sort of scanline fashion. This is because the shader
cores iterate through those pixels in that order, but their values are not being saved in memory
during the duration of the shader core execution.

The important thing to note here is that when the framebuffers are swapped, you can see that the pixels
were colored simultaneously (otherwise only one pixel total would have appeared). This is made very clear
by the fact that you can see many "scan-line" pixels moving simultaneously. If you look carefully, you will
note that there is always only one "scan-line" pixels in a block. This pixel is the one that the shader core
is operating on.

I didn't make as much progress with the demo as I would have liked to. To my knowledge, the actual architecture
is all fully functional. Regardless, the architecture I have designed has lots of potential for expansion. 
You can achieve completely different effects just by using a different fragment shader, and the pipeline
would be able to handle it. Furthermore, I had to use limited resources due the constraints of the board and
our synthesis times. This is an artificial limitation that can be easilychanged.

Further Thoughts
====
I had some more ideas that I did not have time to implement. First of all, I wanted to expand the fragment
shader ISA. I couldn't even implement the subset I planned, so naturally I didn't have the chance to explore
further. I would have wanted to make use of the board's DSP blocks to enable pipelined multiplication, etc.
Another idea would be to have intercore communication. Unfortunately, this was way too ambitious with wiring,
and it turns out there is not much benefit regardless. Finally, I wanted to give shader cores access to the
rendering framebuffer as well. This would allow you to implement, in hardware, techniques that require
evolution of a field over time, such as fluid dynamics or tesselation.